---
layout: about
title: MatCaviar
permalink: /
description: 

profile:
  align: right
  image: zifansong.png
  address: 


news: false  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page



---

## **<font face="Georgia" color="RoyalBlue"><I><B>Zifan</B></I></font>** <font face="Georgia" color="RoyalBlue"><I><B>Song</B></I></font>     
<hr />
<p style="margin-bottom:0.8cm; margin-left: 0.5cm"> </p>
I am a Ph.D candidate in Computer Science and Technology at [<font color="RoyalBlue"><B>Tongji University</B></font>](https://www.tongji.edu.cn/){:target="_blank"}, advised by [<font color="RoyalBlue"><B>Prof. Cairong Zhao</B></font>](https://vill-lab.github.io/){:target="_blank"} and [<font color="RoyalBlue"><B>Guosheng Hu</B></font>](https://huguosheng.github.io/){:target="_blank"}. Prior to this, I obtained my bachelor degree in Computer Science and Technology from [<font color="RoyalBlue"><B>Tongji University</B></font>](https://www.tongji.edu.cn/){:target="_blank"}. After an unforgettable internship in [<font color="RoyalBlue"><B>OpenMMLab</B></font>](https://openmmlab.com/){:target="_blank"} at [<font color="RoyalBlue"><B>Shanghai AI Laboratory</B></font>](https://www.shlab.org.cn/){:target="_blank"} (working with [<font color="RoyalBlue"><B>Dr. Wenwei Zhang</B></font>](http://zhangwenwei.cn/){:target="_blank"} and [<font color="RoyalBlue"><B>Yudong Wang</B></font>](https://github.com/BIGWangYuDong){:target="_blank"}), my current research interests lie in **<font face="Georgia" color="RoyalBlue"><I><B>Multimodal Learning</B></I></font>**, **<font face="Georgia" color="RoyalBlue"><I><B>Data-centric AI</B></I></font>**, and **<font face="Georgia" color="RoyalBlue"><I><B>LLM Agent</B></I></font>**.

<br>

### **News**
<hr />
- [2025/08] I have been invited to serve as a Reviewer for IEEE Transactions on Image Processing, **<font face="Georgia" color="RoyalBlue"><I><B>TIP</B></I></font>**.
- [2025/07] **1 Paper** on Training Paradigm ([**<font face="Georgia"><I><U><B>DPL++</B></U></I></font>**](https://ieeexplore.ieee.org/abstract/document/11106184){:target="_blank"}) is accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence, **<font face="Georgia" color="RoyalBlue"><I><B>TPAMI 2025</B></I></font>**.
- [2025/07] I have been invited to serve as a Reviewer for the 40th Annual AAAI Conference on Artificial Intelligence, **<font face="Georgia" color="RoyalBlue"><I><B>AAAI 2026</B></I></font>**.
- [2025/04] I have been invited to serve as a Reviewer for Advances in Neural Information Processing Systems, **<font face="Georgia" color="RoyalBlue"><I><B>NeurIPS 2025</B></I></font>**.
- [2025/03] I have been invited to serve as a Reviewer for International Conference on Computer Vision, **<font face="Georgia" color="RoyalBlue"><I><B>ICCV 2025</B></I></font>**.
- [2025/03] I will join Microsoft Research Asia (**<font face="Georgia" color="RoyalBlue"><I><B>MSRA</B></I></font>**) to start an internship journey.
- [2025/03] I have been invited to serve as a Reviewer for **<font face="Georgia" color="RoyalBlue"><I><B>ACL</B></I></font>** Rolling Review.
- [2025/02] **1 Paper** on [**<font face="Georgia"><I><U><B>Deepfake Detection</B></U></I></font>**](https://www.sciencedirect.com/science/article/abs/pii/S0031320325001293){:target="_blank"} is accepted by Pattern Recognition, **<font face="Georgia" color="RoyalBlue"><I><B>PR 2025</B></I></font>**.
- [2024/09] **2 Papers** on LLM Fine-tuning ([**<font face="Georgia"><I><U><B>AlchemistCoder</B></U></I></font>**](https://internlm.github.io/AlchemistCoder/){:target="_blank"}) and Video Understanding ([**<font face="Georgia"><I><U><B>Open-Vocabulary Online Action Detection</B></U></I></font>**](https://openreview.net/pdf?id=PWzB2V2b6R){:target="_blank"}) are accepted by Advances in Neural Information Processing Systems, **<font face="Georgia" color="RoyalBlue"><I><B>NeurIPS 2024</B></I></font>**.
- [2024/08] I have been invited to serve as a Reviewer for International Conference on Learning Representations, **<font face="Georgia" color="RoyalBlue"><I><B>ICLR 2025</B></I></font>**.
- [2024/05] **1 Paper** on LLM Pre-training ([***<font face="Georgia"><I><U><B>Code Needs Comments</B></U></I></font>***](https://arxiv.org/abs/2402.13013){:target="_blank"}) is accepted by Annual Meeting of the Association for Computational Linguistics, **<font face="Georgia" color="RoyalBlue"><I><B>ACL 2024</B></I></font>**.
- [2023/12] **1 Paper** on Multimodal Learning ([***<font face="Georgia"><I><U><B>Diverse Person</B></U></I></font>***](https://ojs.aaai.org/index.php/AAAI/article/view/28298){:target="_blank"}) is accepted by Proceedings of the AAAI Conference on Artificial Intelligence, **<font face="Georgia" color="RoyalBlue"><I><B>AAAI 2024</B></I></font>**.
- [2023/09] I will join Shanghai Artificial Intelligence Laboratory (**<font face="Georgia" color="RoyalBlue"><I><B>@OpenMMLab</B></I></font>**) to start an internship journey.
- [2023/08] **1 Paper** on Graph Application ([***<font face="Georgia"><I><U><B>Scene-Pedestrian Graph</B></U></I></font>***](https://ieeexplore.ieee.org/abstract/document/10214025/){:target="_blank"}) is accepted by IEEE Transactions on Industrial Informatics, **<font face="Georgia" color="RoyalBlue"><I><B>TII 2023</B></I></font>**.
- [2023/07] **1 Paper** on Training Paradigm ([***<font face="Georgia"><I><U><B>Deep Perturbation Learning</B></U></I></font>***](https://proceedings.mlr.press/v202/song23c.html){:target="_blank"}) is accepted by International Conference on Machine Learning, **<font face="Georgia" color="RoyalBlue"><I><B>ICML 2023</B></I></font>**.

<br>

### **Publications**
<hr />
<img src="collections/DPL++.png"  width="307" height="123"  align="left" hspace="20" vspace="0"/>
###### **DPL++: Advancing the Network Performance via Image and Label Perturbations** 

**<font face="Georgia" color="RoyalBlue"><I><B>Zifan Song*</B></I></font>**<font face="Georgia"><I>, Xiao Gong, Guosheng Hu, Shuguang Dou, Qingsong Zhao, Cairong Zhao</I></font>

IEEE Transactions on Pattern Analysis and Machine Intelligence, **<font face="Georgia" color="RoyalBlue"><I><B>TPAMI 2025</B></I></font>** 

[[<font color="RoyalBlue"><B>üìÉ Paper</B></font>]](https://ieeexplore.ieee.org/abstract/document/11106184){:target="_blank"}
[[<font color="RoyalBlue"><B>üë®‚Äçüíª Code</B></font>]](https://github.com/Vill-Lab/2023-ICML-DPL){:target="_blank"}

<br>

<img src="collections/AlchemistCoder.png"  width="307" height="173"  align="left" hspace="20" vspace="0"/>
###### **AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight Tuning on Multi-source Data** 

**<font face="Georgia" color="RoyalBlue"><I><B>Zifan Song*</B></I></font>**<font face="Georgia"><I>, Yudong Wang*, Wenwei Zhang*, Kuikun Liu, Chengqi Lyu, Demin Song, Qipeng Guo, Hang Yan, Dahua Lin, Kai Chen, Cairong Zhao</I></font>

Advances in Neural Information Processing Systems, **<font face="Georgia" color="RoyalBlue"><I><B>NeurIPS 2024</B></I></font>** 

[[<font color="RoyalBlue"><B>üìÉ Paper</B></font>]](https://arxiv.org/pdf/2405.19265){:target="_blank"}
[[<font color="RoyalBlue"><B>üë®‚Äçüíª Code</B></font>]](https://github.com/InternLM/AlchemistCoder){:target="_blank"}
[[<font color="RoyalBlue"><B>üåê Project Page</B></font>]](https://internlm.github.io/AlchemistCoder/){:target="_blank"}
[[<font color="RoyalBlue"><B>ü§ó HuggingFace</B></font>]](https://huggingface.co/internlm/AlchemistCoder-DS-6.7B){:target="_blank"}

<br>

<img src="collections/OVOAD.png" width="307" height="158"   align="left" hspace="20" vspace="0"/>
###### **Does Video-Text Pretraining Help Open-Vocabulary Online Action Detection?** 

<font face="Georgia"><I>Qingsong Zhao, Yi Wang, Jilan Xu, Yinan He, </I></font>**<font face="Georgia" color="RoyalBlue"><I><B>Zifan Song</B></I></font>**<font face="Georgia"><I>, Limin Wang, Yu Qiao, Cairong Zhao</I></font>

Advances in Neural Information Processing Systems, **<font face="Georgia" color="RoyalBlue"><I><B>NeurIPS 2024</B></I></font>**

[[<font color="RoyalBlue"><B>üìÉ Paper</B></font>]](https://openreview.net/pdf?id=PWzB2V2b6R){:target="_blank"}

<br>

<img src="collections/CodeNeedComments.png" width="307" height="158"  align="left" hspace="20" vspace="0"/>
###### **Code Needs Comments: Enhancing Code LLMs with Comment Augmentation** 
<font face="Georgia"><I>Demin Song, Honglin Guo, Yunhua Zhou, Shuhao Xing, Yudong Wang, </I></font>**<font face="Georgia" color="RoyalBlue"><I><B>Zifan Song</B></I></font>**<font face="Georgia"><I>, Wenwei Zhang, Qipeng Guo, Hang Yan, Xipeng Qiu, Dahua Lin</I></font>

Annual Meeting of the Association for Computational Linguistics, **<font face="Georgia" color="RoyalBlue"><I><B>ACL 2024</B></I></font>**

[[<font color="RoyalBlue"><B>üìÉ Paper</B></font>]](https://arxiv.org/abs/2402.13013){:target="_blank"}

<br>

<img src="collections/DP.png" width="307" height="137"   align="left" hspace="20" vspace="0"/>
###### **Diverse Person: Customize Your Own Dataset for Text-Based Person Search** 
**<font face="Georgia" color="RoyalBlue"><I><B>Zifan Song</B></I></font>**<font face="Georgia"><I>, Guosheng Hu, Cairong Zhao</I></font>

Proceedings of the AAAI Conference on Artificial Intelligence, **<font face="Georgia" color="RoyalBlue"><I><B>AAAI 2024</B></I></font>**

[[<font color="RoyalBlue"><B>üìÉ Paper</B></font>]](https://ojs.aaai.org/index.php/AAAI/article/view/28298){:target="_blank"}
[[<font color="RoyalBlue"><B>üë®‚Äçüíª Code</B></font>]](https://github.com/Vill-Lab/2024-AAAI-DP){:target="_blank"}

<br>

<img src="collections/SPG.png" width="307" height="137"  align="left" hspace="20" vspace="0"/>
###### **Learning Scene-Pedestrian Graph for End-to-End Person Search** 
**<font face="Georgia" color="RoyalBlue"><I><B>Zifan Song</B></I></font>**<font face="Georgia"><I>, Cairong Zhao, Guosheng Hu, Duoqian Miao</I></font>

IEEE Transactions on Industrial Informatics, **<font face="Georgia" color="RoyalBlue"><I><B>IEEE TII 2023</B></I></font>**

[[<font color="RoyalBlue"><B>üìÉ Paper</B></font>]](https://ieeexplore.ieee.org/abstract/document/10214025/){:target="_blank"}
[[<font color="RoyalBlue"><B>üë®‚Äçüíª Code</B></font>]](https://github.com/Vill-Lab/2023-TII-SPG){:target="_blank"}

<br>

<img src="collections/DPL.png" width="307" height="150"   align="left" hspace="20" vspace="0"/>
###### **Deep perturbation learning: enhancing the network performance via image perturbations** 
**<font face="Georgia" color="RoyalBlue"><I><B>Zifan Song</B></I></font>**<font face="Georgia"><I>, Xiao Gong, Guosheng Hu, Cairong Zhao</I></font>

International Conference on Machine Learning, **<font face="Georgia" color="RoyalBlue"><I><B>ICML 2023</B></I></font>**

[[<font color="RoyalBlue"><B>üìÉ Paper</B></font>]](https://proceedings.mlr.press/v202/song23c.html){:target="_blank"}
[[<font color="RoyalBlue"><B>üë®‚Äçüíª Code</B></font>]](https://github.com/Vill-Lab/2023-ICML-DPL){:target="_blank"}


<br>

### **Pre-Prints**
<hr />
<img src="collections/internlm.png" width="307" height="137"   align="left" hspace="20" vspace="0"/>
###### **InternLM2 Technical Report** 
**<font face="Georgia" color="RoyalBlue"><I><B>InternLM Group</B></I></font>**

ArXiv 2024

[[<font color="RoyalBlue"><B>üìÉ Paper</B></font>]](https://arxiv.org/abs/2403.17297){:target="_blank"}
[[<font color="RoyalBlue"><B>üë®‚Äçüíª Code</B></font>]](https://github.com/internlm/internlm){:target="_blank"}
[[<font color="RoyalBlue"><B>üåê Website</B></font>]](https://internlm.intern-ai.org.cn/){:target="_blank"}

<br>

### **Industry**
<hr />
<div class="industry">
    <div class="table-responsive">
        <table class="table table-sm table-borderless">
          <tr>
            <th scope="row"><span style="font-weight: bold"><font face="Georgia" color="RoyalBlue" size="3"><I><B>Research Intern - ¬ßLLM Fine-tuning</B></I></font></span></th>
            <td>
                <a class="news-title" href="https://openmmlab.com/"><font color="RoyalBlue" size="3"><B>OpenMMLab @ Shanghai AI Laboratory</B></font></a>
            </td>
            <th scope="row"><i></i><font size="3">Sept 2023 - June 2024</font></th>
          </tr>
        </table>
    </div>  
</div>


<br>

### **Education**
<hr />
<div class="education">
    <div class="row">
      <div class="col-md-2">
        <img class="img-fluid z-depth-0.5 rounded" src="collections/tongji.png" width="100px" height="100px">
        <br>
        <br>
        <img class="img-fluid z-depth-0.5 rounded" src="collections/tongji.png" width="100px" height="100px">
      </div>
      <div class="col-md-6">
        <div class="education-details">
        <div><span style="font-weight: bold"><font face="Georgia" color="RoyalBlue"><I><B>Tongji University</B></I></font></span></div>
        <div>Doctoral Student</div><div> Computer Science and Technology</div><div> September 2021 - ???</div>      
        <hr />
        <div class="education-details">
        <div><span style="font-weight: bold"><font face="Georgia" color="RoyalBlue"><I><B>Tongji University</B></I></font></span></div>
        <div>Bachelor Degree</div><div>Computer Science and Technology </div><div> September 2017 - June 2021 </div>      
      </div>
    </div>
  </div>
</div>
</div>

<br>

### **Connections**
<hr />
[<span style="font-weight: bold"><font face="Georgia" color="RoyalBlue"><I><B>Shuguang Dou,</B></I></font></span>](https://shuguang-52.github.io/){:target="_blank"}
[<span style="font-weight: bold"><font face="Georgia" color="RoyalBlue"><I><B>Junyao Gao,</B></I></font></span>](https://jeoyal.github.io/home){:target="_blank"}
[<span style="font-weight: bold"><font face="Georgia" color="RoyalBlue"><I><B>Zefan Qu,</B></I></font></span>](https://quzefan.github.io/){:target="_blank"}
[<span style="font-weight: bold"><font face="Georgia" color="RoyalBlue"><I><B>Yuanpeng Tu,</B></I></font></span>](https://yuanpengtu.github.io/){:target="_blank"}
[<span style="font-weight: bold"><font face="Georgia" color="RoyalBlue"><I><B>Yubin Wang,</B></I></font></span>](https://thomaswangy.github.io/){:target="_blank"}
[<span style="font-weight: bold"><font face="Georgia" color="RoyalBlue"><I><B>Siyuan Li,</B></I></font></span>](https://lupin1998.github.io/){:target="_blank"}
[<span style="font-weight: bold"><font face="Georgia" color="RoyalBlue"><I><B>Yudong Wang,</B></I></font></span>](https://github.com/BIGWangYuDong){:target="_blank"}
[<span style="font-weight: bold"><font face="Georgia" color="RoyalBlue"><I><B>Wenwei Zhang</B></I></font></span>](http://zhangwenwei.cn/){:target="_blank"}

<br>

<center>
<a href="mailto:sugger@tongji.edu.cn" target="_blank"> 
    <img src="collections/email-icon.svg" width="53" target="_blank"/> </a >   &nbsp;&nbsp;&nbsp;
<a href = "https://scholar.google.com/citations?hl=zh-CN&user=D_lQNBUAAAAJ" target="_blank"> 
    <img src="collections/google_scholar-icon.svg" width="63" target="_blank"/></a >   &nbsp;&nbsp;&nbsp;
<a href = "https://github.com/MatCaviar/MatCaviar.github.io" target="_blank">
    <img src="collections/github-icon.svg" width="53" target="_blank"/></a > &nbsp;&nbsp;&nbsp;
</center>
